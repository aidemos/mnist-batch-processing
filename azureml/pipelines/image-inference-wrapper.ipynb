{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved. \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/machine-learning-pipelines/parallel-run/file-dataset-image-inference-mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. cpu-cluster\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import argparse\n",
      "from azureml.core import Dataset, Run\n",
      "from azureml.core.dataset import Dataset\n",
      "from azureml.core import Workspace\n",
      "from azureml.core import Experiment\n",
      "from azureml.pipeline.core import PublishedPipeline\n",
      "\n",
      "parser = argparse.ArgumentParser()\n",
      "parser.add_argument(\"--process_folder_param\", type=str, help=\"process folder path\")\n",
      "args = parser.parse_args()\n",
      "\n",
      "run = Run.get_context()\n",
      "ws = run.experiment.workspace\n",
      "\n",
      "def_data_store = ws.get_default_datastore()\n",
      "mnist_ds_name = 'mnist_version_10_ds_'+ args.process_folder_param\n",
      "print(mnist_ds_name)\n",
      "\n",
      "path_on_datastore = def_data_store.path(args.process_folder_param)\n",
      "input_mnist_ds = Dataset.File.from_files(path=path_on_datastore, validate=False)\n",
      "\n",
      "# input_mnist_ds = input_mnist_ds.register(workspace=ws,\n",
      "#                                  name= mnist_ds_name,\n",
      "#                                  description='mnist images')\n",
      "\n",
      "experiment = Experiment(ws, 'digit_identification')\n",
      "published_pipeline = PublishedPipeline.get(workspace=ws, id=\"880353cd-1950-425a-b54b-1f89b625413e\")\n",
      "pipeline_run = experiment.submit(published_pipeline, \n",
      "                                   pipeline_parameters={\"mnist_param\": input_mnist_ds})\n"
     ]
    }
   ],
   "source": [
    "scripts_folder = \"Code\"\n",
    "dataset_script_file = \"create_file_dataset.py\"\n",
    "\n",
    "# peek at contents\n",
    "with open(os.path.join(scripts_folder, dataset_script_file)) as dataset_file:\n",
    "    print(dataset_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import CondaDependencies, DEFAULT_CPU_IMAGE\n",
    "\n",
    "batch_conda_deps = CondaDependencies.create(pip_packages=[\"azureml-core\", \"azureml-pipeline\"])\n",
    "batch_env = Environment(name=\"aml_environment\")\n",
    "batch_env.python.conda_dependencies = batch_conda_deps\n",
    "batch_env.docker.enabled = True\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.core import RunConfiguration\n",
    "\n",
    "# prepped_data_path = PipelineData(\"dataset_for_inferencing\", def_data_store).as_dataset()\n",
    "process_folder_param = PipelineParameter(name=\"process_folder_param\", default_value=\"mnist/version_1\")\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment = batch_env\n",
    "\n",
    "inference_step = PythonScriptStep(\n",
    "    script_name=dataset_script_file,\n",
    "    name=\"single-inference\",\n",
    "    arguments=[\"--process_folder_param\", process_folder_param],\n",
    "    compute_target=compute_target,\n",
    "    source_directory=scripts_folder,\n",
    "    runconfig = run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step single-inference [3bdde023][40d38723-ed2f-40be-9c96-f392618ab4d9], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 67e3ea25-9375-45cf-8df0-dd7a6bda36f7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/digit_identification/runs/67e3ea25-9375-45cf-8df0-dd7a6bda36f7?wsid=/subscriptions/d661a889-c8b8-41f2-93ab-99b3ed99b6e7/resourcegroups/AMLPoC/workspaces/amlpocmlws\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[inference_step])\n",
    "experiment = Experiment(ws, 'digit_identification')\n",
    "pipeline_run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the run\n",
    "\n",
    "The pipeline run status could be checked in Azure Machine Learning portal (https://ml.azure.com). The link to the pipeline run could be retrieved by inspecting the `pipeline_run` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>digit_identification</td><td>f9ce4d75-688b-4311-a1d3-8ebc1f94c840</td><td>azureml.PipelineRun</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/experiments/digit_identification/runs/f9ce4d75-688b-4311-a1d3-8ebc1f94c840?wsid=/subscriptions/d661a889-c8b8-41f2-93ab-99b3ed99b6e7/resourcegroups/AMLPoC/workspaces/amlpocmlws\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: digit_identification,\n",
       "Id: f9ce4d75-688b-4311-a1d3-8ebc1f94c840,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: NotStarted)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will output information of the pipeline run, including the link to the details page of portal.\n",
    "pipeline_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: View detailed logs (streaming) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: ab497d76-e504-4937-b0a0-6fc26137824e\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/digit_identification/runs/ab497d76-e504-4937-b0a0-6fc26137824e?wsid=/subscriptions/d661a889-c8b8-41f2-93ab-99b3ed99b6e7/resourcegroups/AMLPoC/workspaces/amlpocmlws\n",
      "PipelineRun Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'ab497d76-e504-4937-b0a0-6fc26137824e', 'status': 'Completed', 'startTimeUtc': '2020-12-17T14:48:55.844577Z', 'endTimeUtc': '2020-12-17T15:07:15.18294Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"batch_size_param\":\"5\",\"process_count_param\":\"2\"}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlpocwsstorage.blob.core.windows.net/azureml/ExperimentRun/dcid.ab497d76-e504-4937-b0a0-6fc26137824e/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=6iWTXU5jT9OuZd9SloQT4oLLTDM%2B8hT%2FkdcbDZEH1c8%3D&st=2020-12-17T14%3A39%3A20Z&se=2020-12-17T22%3A49%3A20Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlpocwsstorage.blob.core.windows.net/azureml/ExperimentRun/dcid.ab497d76-e504-4937-b0a0-6fc26137824e/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=TI3UDTFv%2B%2FyKtMHuJlHomZ43O%2BSLfdk3BnkEPb2zMck%3D&st=2020-12-17T14%3A39%3A20Z&se=2020-12-17T22%3A49%3A20Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlpocwsstorage.blob.core.windows.net/azureml/ExperimentRun/dcid.ab497d76-e504-4937-b0a0-6fc26137824e/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=iSWydvkvoxqbHrJnYRRi%2BMMdwLt2MXc1r6PlSBtdF94%3D&st=2020-12-17T14%3A39%3A20Z&se=2020-12-17T22%3A49%3A20Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait the run for completion and show output log to console\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Compute resources\n",
    "\n",
    "For re-occurring jobs, it may be wise to keep compute the compute resources and allow compute nodes to scale down to 0. However, since this is just a single-run job, we are free to release the allocated compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below and run if compute resources are no longer needed \n",
    "compute_target.delete() "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "joringer"
   },
   {
    "name": "asraniwa"
   },
   {
    "name": "pansav"
   },
   {
    "name": "tracych"
   }
  ],
  "categories": [
   "how-to-use-azureml",
   "machine-learning-pipelines",
   "parallel-run"
  ],
  "category": "Other notebooks",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "MNIST"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "None"
  ],
  "friendly_name": "MNIST data inferencing using ParallelRunStep",
  "index_order": 1,
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "tags": [
   "Batch Inferencing",
   "Pipeline"
  ],
  "task": "Digit identification"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
